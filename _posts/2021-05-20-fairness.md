---
layout: post
title: Fairness in Machine Learning
date_event: 2021-06-01T10:20:00Z
tag: upcoming
image: "/images/illustration/event8-fairness.jpg"
permalink: /event-8/
---

**The talk is planned for the 01/06/2021 at 17:00 CET: [link](https://dtudk.zoom.us/j/64170158299?pwd=aHJjbHRCYXhacVBvMnRqclcvS0Z0UT09).**

- [Lydia Liu](https://lydiatliu.github.io/) is a PhD student at Berkeley, under the supervision of Moritz Hardt and Michael Jordan. Her research lies on the theoretical foundations of machine learning and algorithmic decision-making, with a focus on societal impact and human welfare. She also received the Best paper award, at ICML 2018, for her paper: ‘Delayed Impact of Fair Machine Learning’.

- [Pola Schwöbel](https://www.dtu.dk/english/about/press-room/articles/nyhed?id=375e1e4f-bbdd-4523-a89f-5ca287614ac5) is a PhD at the Technical University of Denmark, her research focuses on Probabilistic Machine Learning and Fairness. She will present a joint work with Dr. Peter Remmers about Fairness from a philosophical perspective, and will give an overview of the different metrics used in fairness.

- Dr. [Dirk Hovy](http://www.dirkhovy.com/index.php) is an associate professor at Bocconi University, and also director of the Data and Marketing Insights research unit at the Bocconi Center for Data Science and Analytics. His research focuses on computational social science and he works in Natural Language Processing (NLP). He will give us an overview on demographic bias in NLP models.
